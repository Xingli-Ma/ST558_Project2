y = "Number of Users",
color='Month')
dayTrainCopy <- dayTrain
levels(dayTrainCopy$mnth) <- list("Jan" = 1, "Feb" = 2, "Mar" = 3, "Apr" = 4,
"May" = 5, "Jun" = 6, "Jul" = 7, "Aug" = 8,
"Sep" = 9, "Oct" = 10, "Nov" = 11, "Dec" = 12)
g <- ggplot(dayTrainCopy, aes(x = mnth, y = cnt))
g + geom_boxplot() +
geom_point(aes(col = mnth), alpha = 1, size = 1, position = "jitter") +
labs(title = "Boxplot for Number of Users by Month",
x = "Month",
y = "Number of Users",
color='Month')
dayTrainCopy
min(dayTrainCopy$cnt)
mean(filter(dayTrainCopy, mnth=10))
dayTrainCopyOct <- filter(dayTrainCopy, mnth=10)
dayTrainCopyOct <- filter(dayTrainCopy, mnth="Oct")
dayTrainCopyOct <- filter(dayTrain, mnth="Oct")
dayTrainCopyOct <- filter(dayTrain, mnth=10)
dayTrainCopyOct <- filter(dayTrain, mnth==10)
dayTrainCopyOct
mean(dayTrainCopyOct$cnt)
dayTrainCopy <- dayTrain
levels(dayTrainCopy$mnth) <- list("Jan" = 1, "Feb" = 2, "Mar" = 3, "Apr" = 4,
"May" = 5, "Jun" = 6, "Jul" = 7, "Aug" = 8,
"Sep" = 9, "Oct" = 10, "Nov" = 11, "Dec" = 12)
g <- ggplot(dayTrainCopy, aes(x = mnth, y = cnt))
g + geom_boxplot() +
geom_point(aes(col = mnth), alpha = 1, size = 1, position = "jitter") +
labs(title = "Boxplot for Number of Users by Month",
x = "Month",
y = "Number of Users",
color='Month')
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ temp, data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ weatherslt + temp + atemp + hum + windspeed,
data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
dayTrain
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ weathersit + temp + atemp + hum + windspeed,
data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ weathersit*temp*atemp*hum*windspeed,
data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ weathersit + temp + atemp + hum + windspeed,
data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ weathersit + temp + atemp + hum + windspeed +
I(`weathersit`^2) + I(`temp`^2) + I(`atemp`^2) + I(`hum`^2) +
I(`windspeed`^2),
data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ weathersit + temp + atemp + hum + windspeed +
I(`temp`^2) + I(`atemp`^2) + I(`hum`^2) +
I(`windspeed`^2),
data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ temp + atemp + hum + windspeed +
I(`temp`^2) + I(`atemp`^2) + I(`hum`^2) +
I(`windspeed`^2),
data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ weathersit + temp + atemp + hum + windspeed +
I(`temp`^2) + I(`atemp`^2) + I(`hum`^2) +
I(`windspeed`^2),
data = dayTrain,
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ weathersit + temp + atemp + hum + windspeed +
I(`temp`^2) + I(`atemp`^2) + I(`hum`^2) +
I(`windspeed`^2),
data = dayTrain,
method = "glm",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, warning = FALSE, error = TRUE)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ .,
data = select(dayTrain, -c(registered, casual)),
method = "glm",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, warning = FALSE, error = TRUE)
library(tidyverse)
library(knitr)
library(caret)
# Read and clean data
dayData <- read_csv("day.csv")
dayData <- filter(dayData, weekday == params$day)
dayData <- select(dayData, -c(instant, weekday))
dayData$dteday = as.Date(dayData$dteday, format = "%Y-%m-%d")
# Split data to train and test sets
set.seed(1)
dayIndex <- createDataPartition(dayData$cnt, p = 0.7, list = FALSE)
dayTrain <- dayData[dayIndex, ]
dayTest <- dayData[-dayIndex, ]
# Convert categorical variables to factors
cols <- c("season", "yr", "mnth", "holiday", "workingday", "weathersit")
dayTrain[cols] <- lapply(dayTrain[cols], factor)
dayTest[cols] <- lapply(dayTest[cols], factor)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ .,
data = select(dayTrain, -c(registered, casual)),
method = "glm",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ .^2,
data = select(dayTrain, -c(registered, casual)),
method = "glm",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ .,
data = select(dayTrain, -c(registered, casual)),
method = "glm",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the random forest model with cnt as response and all other variables as
# predictors on training set
rfFit <- train(cnt ~ ., data = select(dayTrain, -c(registered, casual)),
method = "rf",
preProcess = c("center", "scale"),
trControl = trctrl)
rfFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ .,
data = select(dayTrain, -c(registered, casual)),
method = "glm",
family = "poisson",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ .^2,
data = select(dayTrain, -c(registered, casual)),
method = "glm",
family = "poisson",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ .,
data = select(dayTrain, -c(registered, casual)),
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ .,
data = select(dayTrain, -c(registered, casual)),
method = "lm",
family = "binomial",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
lmFit <- train(cnt ~ .,
data = select(dayTrain, -c(registered, casual)),
method = "lm",
preProcess = c("center", "scale"),
trControl = trctrl)
lmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
lmFit <- train(cnt ~ .,
data = select(dayTrain, -c(registered, casual)),
method = "glm",
family= "poisson",
preProcess = c("center", "scale"),
trControl = trctrl)
lmFit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(123)
# Fit the linear regression model with cnt as response and weather predictors on training set
glmFit <- train(cnt ~ weathersit + temp + atemp + hum + windspeed +
I(`temp`^2) + I(`atemp`^2) + I(`hum`^2) +
I(`windspeed`^2),
data = select(dayTrain, -c(registered, casual)),
method = "glm",
preProcess = c("center", "scale"),
trControl = trctrl)
glmFit
#install.packages("formatR")
library(formatR)
library(tidyverse)
library(class)
library(caret)
#install.packages("randomForest")
library(randomForest)
#install.packages("gbm")
library(gbm)
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, error = TRUE, warning = FALSE, message = FALSE, cache = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)
# Read in the data
diabetesData <- read.csv(file = "C:/Users/Xingli/Documents/ST/ST558/hw11/dataset_37_diabetes.csv")
# Convert class variable as a factor
diabetesData$class <- as.factor(diabetesData$class)
# Make our modeling reproducible
set.seed(558)
# Create row indices for training dataset, including 80% of the full data,
train <- sample(1:nrow(diabetesData), size = nrow(diabetesData)*0.8)
# Create row indices for testing dataset, including the rest of 20% of the full data,
test <- dplyr::setdiff(1:nrow(diabetesData), train)
# Split the full dataset into training set and testing set given the observation
# indices for training/testing set
diabetesDataTrain <- diabetesData[train, ]
diabetesDataTest <- diabetesData[test, ]
# Check the structure of the test dataset
str(diabetesDataTrain)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the classification tree model with class as response and all other variables
# as predictors on training set
classTree_fit <- train(class ~ ., data = diabetesDataTrain,
method = "rpart",
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale"), # Standardize the training dataset
# Set tuning parameter from 0 to 0.1 by 0.001
tuneGrid = expand.grid(cp = seq(0, 0.1, 0.001)))
classTree_fit
# Set seed for reproducible
set.seed(558)
# Use predict() to make prediction on testing set
test_pred_classTree <- predict(classTree_fit, newdata = diabetesDataTest)
# Create the confusion matrix to calculate the prediction accuracy
confusionMatrix(test_pred_classTree, diabetesDataTest$class)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the bagged tree model with class as response and all other variables as
# predictors on training set
baggedTree_fit <- train(class ~ ., data = diabetesDataTrain,
method = "treebag",
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale")) # Standardize the training dataset
baggedTree_fit
# Set seed for reproducible
set.seed(558)
# Use predict() to make prediction on testing set
test_pred_baggedTree <- predict(baggedTree_fit, newdata = diabetesDataTest)
# Create the confusion matrix to calculate the prediction accuracy
confusionMatrix(test_pred_baggedTree, diabetesDataTest$class)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the random forest model with class as response and all other variables as
# predictors on training set
rf_fit <- train(class ~ ., data = diabetesDataTrain,
method = "rf",
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale"), # Standardize the training dataset
tuneGrid = data.frame(mtry = 1:8)) # Fit model including 1, 2, ..., 8 predictors
rf_fit
# Set seed for reproducible
set.seed(558)
# Use predict() to make prediction on testing set
test_pred_rf <- predict(rf_fit, newdata = diabetesDataTest)
# Create the confusion matrix to calculate the prediction accuracy
confusionMatrix(test_pred_rf, diabetesDataTest$class)
diabetesDataTrain$class <- as.factor(diabetesDataTrain$class)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the boosted tree model with class as response and all other variables as
# predictors on training set
boostedTree_fit <- train(class ~., data = diabetesDataTrain,
method = "gbm",
verbose = FALSE,
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale")) # Standardize the training dataset
boostedTree_fit
# Set seed for reproducible
set.seed(558)
# Use predict() to make prediction on testing set
test_pred_boostedTree <- predict(boostedTree_fit, newdata = diabetesDataTest)
# Create the confusion matrix to calculate the prediction accuracy
confusionMatrix(test_pred_boostedTree, diabetesDataTest$class)
diabetesDataTrain$class <- as.factor(diabetesDataTrain$class)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the boosted tree model with class as response and all other variables as
# predictors on training set
boostedTree_fit <- train(class ~., data = diabetesDataTrain,
method = "gbm",
verbose = FALSE,
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale"), # Standardize the training dataset
n.trees = 300,
interaction.depth =4,
shrinkage = 0.1,
n.minobsinnode = 30)
diabetesDataTrain$class <- as.factor(diabetesDataTrain$class)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the boosted tree model with class as response and all other variables as
# predictors on training set
boostedTree_fit <- train(class ~., data = diabetesDataTrain,
method = "gbm",
verbose = FALSE,
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale")) # Standardize the training dataset
diabetesDataTrain$class <- as.factor(diabetesDataTrain$class)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the boosted tree model with class as response and all other variables as
# predictors on training set
boostedTree_fit <- train(class ~., data = diabetesDataTrain,
method = "gbm",
verbose = FALSE,
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale")) # Standardize the training dataset
boostedTree_fit
diabetesDataTrain$class <- as.factor(diabetesDataTrain$class)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the boosted tree model with class as response and all other variables as
# predictors on training set
boostedTree_fit <- train(class ~., data = diabetesDataTrain,
method = "gbm",
verbose = FALSE,
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale"), # Standardize the training dataset
n.trees = 300,
interaction.depth =4,
shrinkage = 0.1,
n.minobsinnode = 30))
boostedTree_fit
diabetesDataTrain$class <- as.factor(diabetesDataTrain$class)
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Fit the boosted tree model with class as response and all other variables as
# predictors on training set
boostedTree_fit <- train(class ~., data = diabetesDataTrain,
method = "gbm",
verbose = FALSE,
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale"), # Standardize the training dataset
n.trees = 300,
interaction.depth =4,
shrinkage = 0.1,
n.minobsinnode = 30)
boostedTree_fit
# Set up fold number (10) for the cross validation and the repeated times (5) of the whole CV
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Set seed for reproducible
set.seed(558)
# Set up tuning parameters
gbmGrid <-  expand.grid(interaction.depth = c(1, 2, 3, 4, 5, 10),
n.trees = c(50, 100, 150),
shrinkage = seq(0.05, 0.2, 0.01),
n.minobsinnode = c(5, 10, 15, 20))
# Fit the boosted tree model with class as response and all other variables as
# predictors on training set
boostedTree_fit <- train(class ~., data = diabetesDataTrain,
method = "gbm",
trControl = trctrl, # Passing trainControl() method
preProcess = c("center", "scale"), # Standardize the training dataset
tuneGrid = gbmGrid,
verbose = FALSE)
